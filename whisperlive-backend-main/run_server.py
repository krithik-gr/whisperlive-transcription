import socketio
import eventlet
from faster_whisper import WhisperModel
import numpy as np
import tempfile
import soundfile as sf

sio = socketio.Server(cors_allowed_origins='*')
app = socketio.WSGIApp(sio)

print("ğŸ”„ Loading Whisper model...")
model = WhisperModel("base")
print("âœ… Whisper model loaded!")

@sio.event
def connect(sid, environ):
    print(f"ğŸ”Œ Client connected: {sid}")

@sio.event
def disconnect(sid):
    print(f"âŒ Client disconnected: {sid}")

@sio.event
def audio_blob(sid, blob_data):
    print(f"ğŸµ Received audio blob from {sid} - {len(blob_data)} bytes")
    try:
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=True) as f:
            f.write(blob_data)
            f.flush()
            audio, _ = sf.read(f.name, dtype='float32')

        segments, _ = model.transcribe(audio)
        full_text = " ".join(segment.text for segment in segments).strip()

        if full_text:
            print(f"ğŸ“ Transcribed: {full_text}")
            sio.emit("transcription", full_text, to=sid)
        else:
            print("ğŸ”‡ No speech detected.")
    except Exception as e:
        print(f"âš ï¸ Error decoding/transcribing blob: {e}")
        sio.emit("transcription", '', to=sid)

if __name__ == '__main__':
    print("ğŸš€ Starting WhisperLive backend on port 5000...")
    eventlet.wsgi.server(eventlet.listen(('0.0.0.0', 5000)), app)
